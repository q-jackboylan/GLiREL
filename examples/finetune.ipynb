{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4600e0c3-8e8d-4f7d-b0fc-5b39ee2ddeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from glirel.model import GLiREL\n",
    "\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from glirel.model import load_config_as_namespace\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from train import train, dirty_split_data_by_relation_type\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e95da4b",
   "metadata": {},
   "source": [
    "## üèéÔ∏è Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bef30385-7814-4f36-89e8-f2c79a7b57c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jackboylan/miniconda3/envs/glirel/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:550: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = GLiREL.from_pretrained(\"jackboyla/glirel_beta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732ca6ce",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d13481a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file_path = '../configs/config_finetuning.yaml'\n",
    "log_dir = '../logs/finetuning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c5c87e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, \n",
    "                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "                    handlers=[logging.StreamHandler()])\n",
    "\n",
    "\n",
    "# load config\n",
    "config = load_config_as_namespace(config_file_path)\n",
    "\n",
    "config.log_dir = log_dir\n",
    "config.train_data = train_path\n",
    "\n",
    "# set up logging\n",
    "if config.log_dir is None:\n",
    "    current_time = datetime.now().strftime(\"%Y-%m-%d__%H-%M-%S\")\n",
    "    config.log_dir = f'logs/{config.dataset_name}/{config.dataset_name}-{current_time}'\n",
    "if not os.path.exists(config.log_dir):\n",
    "    os.makedirs(config.log_dir)\n",
    "\n",
    "log_file = \"train.log\"\n",
    "log_file_path = os.path.join(config.log_dir, log_file)\n",
    "if os.path.exists(log_file_path):\n",
    "    os.remove(log_file_path)\n",
    "file_handler = logging.FileHandler(log_file_path)\n",
    "file_handler.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "file_handler.setFormatter(formatter)\n",
    "logger.addHandler(file_handler)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498b227a",
   "metadata": {},
   "source": [
    "## üìì Prep Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f57ff1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-25 15:59:52,494 - train - INFO - Dirty splitting data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting training data into training and test sets with max test size: 1\n",
      "Train dataset size: 4\n",
      "Test dataset size: 1\n"
     ]
    }
   ],
   "source": [
    "train_path = \"../data/sample.jsonl\" # cannot be None\n",
    "test_path = None  # can be None\n",
    "\n",
    "assert os.path.exists(train_path), f\"Train file not found: {train_path}\"\n",
    "\n",
    "with open(train_path, \"r\") as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "\n",
    "random.shuffle(data)\n",
    "\n",
    "TEST_SET_RATIO = 0.1\n",
    "TRAIN_SET_RATIO = 1 - TEST_SET_RATIO\n",
    "\n",
    "\n",
    "if test_path is None:\n",
    "    # if no test set provided, split the training data\n",
    "    max_test_size = round(len(data)*TEST_SET_RATIO) + 1\n",
    "    print(f\"Splitting training data into training and test sets with max test size: {max_test_size}\")\n",
    "    train_dataset, test_dataset = dirty_split_data_by_relation_type(\n",
    "        data, \n",
    "        num_unseen_rel_types=config.num_unseen_rel_types, \n",
    "        max_test_size=max_test_size,\n",
    "        )\n",
    "else:\n",
    "    train_dataset = data\n",
    "    with open(test_path, \"r\") as f:\n",
    "        test_dataset = [json.loads(line) for line in f]\n",
    "\n",
    "print('Train dataset size:', len(train_dataset))\n",
    "print('Test dataset size:', len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47473113",
   "metadata": {},
   "source": [
    "## üöÄ Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2063a88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-25 15:59:52,516 - __main__ - INFO - Number of trainable parameters: 466576896 / 466576896\n",
      "2024-07-25 15:59:52,527 - __main__ - INFO - üöÄ Relation extraction training started\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]2024-07-25 15:59:56,139 - train - INFO - Step 0 | loss: 31.11713218688965 | x['rel_label']: torch.Size([4, 2]) | x['span_idx']: torch.Size([4, 2, 2]) | x['tokens']: [24, 28, 25, 30] | num candidate_classes: 4\n",
      "step: 0 | epoch: 0 | loss: 31.12:   5%|‚ñç         | 1/21 [00:05<01:58,  5.93s/it]2024-07-25 16:00:02,168 - train - INFO - Step 1 | loss: 31.591588973999023 | x['rel_label']: torch.Size([4, 2]) | x['span_idx']: torch.Size([4, 2, 2]) | x['tokens']: [24, 28, 25, 30] | num candidate_classes: 4\n",
      "step: 1 | epoch: 1 | loss: 31.59:  10%|‚ñâ         | 2/21 [00:11<01:43,  5.46s/it]2024-07-25 16:00:06,928 - train - INFO - Step 2 | loss: 14.576828002929688 | x['rel_label']: torch.Size([4, 2]) | x['span_idx']: torch.Size([4, 2, 2]) | x['tokens']: [24, 28, 25, 30] | num candidate_classes: 4\n",
      "step: 2 | epoch: 2 | loss: 14.58:  14%|‚ñà‚ñç        | 3/21 [00:15<01:32,  5.13s/it]2024-07-25 16:00:11,724 - train - INFO - Step 3 | loss: 16.596786499023438 | x['rel_label']: torch.Size([4, 2]) | x['span_idx']: torch.Size([4, 2, 2]) | x['tokens']: [24, 28, 25, 30] | num candidate_classes: 4\n",
      "step: 3 | epoch: 3 | loss: 16.60:  19%|‚ñà‚ñâ        | 4/21 [00:20<01:24,  4.98s/it]2024-07-25 16:00:20,838 - train - INFO - Step 4 | loss: 11.732481002807617 | x['rel_label']: torch.Size([4, 2]) | x['span_idx']: torch.Size([4, 2, 2]) | x['tokens']: [24, 28, 25, 30] | num candidate_classes: 4\n",
      "step: 4 | epoch: 4 | loss: 11.73:  24%|‚ñà‚ñà‚ñç       | 5/21 [00:31<01:55,  7.25s/it]2024-07-25 16:00:30,786 - train - INFO - Step 5 | loss: 9.95985221862793 | x['rel_label']: torch.Size([4, 2]) | x['span_idx']: torch.Size([4, 2, 2]) | x['tokens']: [24, 28, 25, 30] | num candidate_classes: 4\n",
      "step: 5 | epoch: 5 | loss: 9.96:  29%|‚ñà‚ñà‚ñä       | 6/21 [00:40<01:53,  7.57s/it] 2024-07-25 16:00:35,968 - train - INFO - Step 6 | loss: 11.812854766845703 | x['rel_label']: torch.Size([4, 2]) | x['span_idx']: torch.Size([4, 2, 2]) | x['tokens']: [24, 28, 25, 30] | num candidate_classes: 4\n",
      "step: 6 | epoch: 6 | loss: 11.81:  33%|‚ñà‚ñà‚ñà‚ñé      | 7/21 [00:45<01:35,  6.81s/it]2024-07-25 16:00:41,738 - train - INFO - Step 7 | loss: 8.28909683227539 | x['rel_label']: torch.Size([4, 2]) | x['span_idx']: torch.Size([4, 2, 2]) | x['tokens']: [24, 28, 25, 30] | num candidate_classes: 4\n",
      "step: 7 | epoch: 7 | loss: 8.29:  38%|‚ñà‚ñà‚ñà‚ñä      | 8/21 [00:50<01:22,  6.37s/it] 2024-07-25 16:00:46,789 - train - INFO - Step 8 | loss: 6.000664710998535 | x['rel_label']: torch.Size([4, 2]) | x['span_idx']: torch.Size([4, 2, 2]) | x['tokens']: [24, 28, 25, 30] | num candidate_classes: 4\n",
      "step: 8 | epoch: 8 | loss: 6.00:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 9/21 [00:55<01:11,  5.94s/it]2024-07-25 16:00:51,668 - train - INFO - Step 9 | loss: 7.230718612670898 | x['rel_label']: torch.Size([4, 2]) | x['span_idx']: torch.Size([4, 2, 2]) | x['tokens']: [24, 28, 25, 30] | num candidate_classes: 4\n",
      "step: 9 | epoch: 9 | loss: 7.23:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 10/21 [01:00<01:01,  5.62s/it]2024-07-25 16:00:56,673 - train - INFO - Step 10 | loss: 6.574692726135254 | x['rel_label']: torch.Size([4, 2]) | x['span_idx']: torch.Size([4, 2, 2]) | x['tokens']: [24, 28, 25, 30] | num candidate_classes: 4\n",
      "step: 10 | epoch: 10 | loss: 6.57:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 11/21 [01:05<00:54,  5.42s/it]2024-07-25 16:01:01,796 - train - INFO - Step 11 | loss: 5.963137626647949 | x['rel_label']: torch.Size([4, 2]) | x['span_idx']: torch.Size([4, 2, 2]) | x['tokens']: [24, 28, 25, 30] | num candidate_classes: 4\n",
      "step: 11 | epoch: 11 | loss: 5.96:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 12/21 [01:10<00:48,  5.39s/it]2024-07-25 16:01:07,091 - train - INFO - Step 12 | loss: 4.860792636871338 | x['rel_label']: torch.Size([4, 2]) | x['span_idx']: torch.Size([4, 2, 2]) | x['tokens']: [24, 28, 25, 30] | num candidate_classes: 4\n",
      "step: 12 | epoch: 12 | loss: 4.86:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 13/21 [01:16<00:42,  5.32s/it]2024-07-25 16:01:12,028 - train - INFO - Step 13 | loss: 4.316626071929932 | x['rel_label']: torch.Size([4, 2]) | x['span_idx']: torch.Size([4, 2, 2]) | x['tokens']: [24, 28, 25, 30] | num candidate_classes: 4\n",
      "step: 13 | epoch: 13 | loss: 4.32:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 14/21 [01:20<00:36,  5.21s/it]2024-07-25 16:01:17,075 - train - INFO - Step 14 | loss: 4.0842390060424805 | x['rel_label']: torch.Size([4, 2]) | x['span_idx']: torch.Size([4, 2, 2]) | x['tokens']: [24, 28, 25, 30] | num candidate_classes: 4\n",
      "step: 14 | epoch: 14 | loss: 4.08:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 15/21 [01:26<00:31,  5.18s/it]2024-07-25 16:01:22,276 - train - INFO - Step 15 | loss: 3.7353219985961914 | x['rel_label']: torch.Size([4, 2]) | x['span_idx']: torch.Size([4, 2, 2]) | x['tokens']: [24, 28, 25, 30] | num candidate_classes: 4\n",
      "step: 15 | epoch: 15 | loss: 3.74:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 16/21 [01:31<00:25,  5.13s/it]2024-07-25 16:01:27,293 - train - INFO - Step 16 | loss: 3.608715772628784 | x['rel_label']: torch.Size([4, 2]) | x['span_idx']: torch.Size([4, 2, 2]) | x['tokens']: [24, 28, 25, 30] | num candidate_classes: 4\n",
      "step: 16 | epoch: 16 | loss: 3.61:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 17/21 [01:36<00:20,  5.10s/it]2024-07-25 16:01:32,229 - train - INFO - Step 17 | loss: 15.925634384155273 | x['rel_label']: torch.Size([4, 2]) | x['span_idx']: torch.Size([4, 2, 2]) | x['tokens']: [24, 28, 25, 30] | num candidate_classes: 4\n",
      "step: 17 | epoch: 17 | loss: 15.93:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 18/21 [01:41<00:15,  5.06s/it]2024-07-25 16:01:37,113 - train - INFO - Step 18 | loss: 4.375746726989746 | x['rel_label']: torch.Size([4, 2]) | x['span_idx']: torch.Size([4, 2, 2]) | x['tokens']: [24, 28, 25, 30] | num candidate_classes: 4\n",
      "step: 18 | epoch: 18 | loss: 4.38:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 19/21 [01:46<00:10,  5.04s/it] 2024-07-25 16:01:42,133 - train - INFO - Step 19 | loss: 3.389799118041992 | x['rel_label']: torch.Size([4, 2]) | x['span_idx']: torch.Size([4, 2, 2]) | x['tokens']: [24, 28, 25, 30] | num candidate_classes: 4\n",
      "2024-07-25 16:01:43,581 - train - INFO - Time taken for 20 steps: 111 seconds\n",
      "2024-07-25 16:01:49,878 - train - INFO - Model saved at ../logs/finetuning/model_20\n",
      "2024-07-25 16:01:49,879 - train - INFO - Evaluating...\n",
      "2024-07-25 16:01:49,880 - train - INFO - Taking top k = 1 predictions for each relation...\n",
      "2024-07-25 16:01:49,883 - glirel.model - INFO - Number of classes to evaluate with --> 1\n",
      "2024-07-25 16:01:49,886 - glirel.model - INFO - ## Evaluation x['classes_to_id'] (showing 15/1) --> ['original network']\n",
      "2024-07-25 16:01:50,494 - train - INFO - Step=19\n",
      "Micro P: 100.00%\tMicro R: 100.00%\tMicro F1: 100.00%\n",
      "Macro P: 100.00%\tMacro R: 100.00%\tMacro F1: 100.00%\n",
      "\n",
      "step: 19 | epoch: 19 | loss: 3.39:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 20/21 [01:58<00:07,  7.18s/it]2024-07-25 16:01:54,428 - train - INFO - Step 20 | loss: 3.621650457382202 | x['rel_label']: torch.Size([4, 2]) | x['span_idx']: torch.Size([4, 2, 2]) | x['tokens']: [24, 28, 25, 30] | num candidate_classes: 4\n",
      "step: 20 | epoch: 20 | loss: 3.62: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 21/21 [02:03<00:00,  5.88s/it]\n"
     ]
    }
   ],
   "source": [
    "# Get number of parameters (trainable and total)\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "num_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "logger.info(f\"Number of trainable parameters: {num_trainable_params} / {num_params}\")\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "lr_encoder = float(config.lr_encoder)\n",
    "lr_others = float(config.lr_others)\n",
    "\n",
    "optimizer = torch.optim.AdamW([\n",
    "    # encoder\n",
    "    {'params': model.token_rep_layer.parameters(), 'lr': lr_encoder},\n",
    "    {'params': model.rnn.parameters(), 'lr': lr_others},\n",
    "    # projection layers\n",
    "    {'params': model.span_rep_layer.parameters(), 'lr': lr_others},\n",
    "    {'params': model.prompt_rep_layer.parameters(), 'lr': lr_others},\n",
    "])\n",
    "\n",
    "\n",
    "logger.info(\"üöÄ Relation extraction training started\")\n",
    "train(model, \n",
    "      optimizer, \n",
    "      train_dataset, \n",
    "      config, \n",
    "      eval_data=test_dataset, \n",
    "      num_steps=config.num_steps, \n",
    "      eval_every=config.eval_every, \n",
    "      log_dir=config.log_dir,\n",
    "      wandb_log=False, \n",
    "      wandb_sweep=False, \n",
    "      warmup_ratio=config.warmup_ratio, \n",
    "      train_batch_size=config.train_batch_size, \n",
    "      device=DEVICE,\n",
    "      use_amp=True if DEVICE == 'cuda' else False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cefe5c",
   "metadata": {},
   "source": [
    "## ü•≥ Load your finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "040ebb95-bba1-440d-89c8-5499448b560b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json not found in /home/jackboylan/GLiREL/logs/finetuning/model_20\n",
      "2024-07-25 16:02:44,632 - huggingface_hub.hub_mixin - WARNING - config.json not found in /home/jackboylan/GLiREL/logs/finetuning/model_20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of relations: 2\n",
      "\n",
      "Descending Order by Score:\n",
      "['Marco', 'Polo'] --> characters --> ['First', 'Doctor'] | score: 0.7750263810157776\n",
      "['First', 'Doctor'] --> characters --> ['Marco', 'Polo'] | score: 0.573470413684845\n"
     ]
    }
   ],
   "source": [
    "model = GLiREL.from_pretrained(f\"{config.log_dir}/model_{config.eval_every}\")\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "text = 'Derren Nesbitt had a history of being cast in \"Doctor Who\", having played villainous warlord Tegana in the 1964 First Doctor serial \"Marco Polo\".'\n",
    "doc = nlp(text)\n",
    "tokens = [token.text for token in doc]\n",
    "\n",
    "labels = ['country of origin', 'licensed to broadcast to', 'father', 'followed by', 'characters']\n",
    "\n",
    "ner = [[26, 27, 'PERSON', 'Marco Polo'], [22, 23, 'Q2989412', 'First Doctor']] \n",
    "\n",
    "relations = model.predict_relations(tokens, labels, threshold=0.0, ner=ner, top_k=1)\n",
    "\n",
    "print('Number of relations:', len(relations))\n",
    "\n",
    "sorted_data_desc = sorted(relations, key=lambda x: x['score'], reverse=True)\n",
    "print(\"\\nDescending Order by Score:\")\n",
    "for item in sorted_data_desc:\n",
    "    print(f\"{item['head_text']} --> {item['label']} --> {item['tail_text']} | score: {item['score']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81cae65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
