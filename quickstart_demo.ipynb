{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸšž Zero-shot RE Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if you're running this in a colab notebook, you can run this cell to install the necessary dependencies\n",
    "# pip install glirel\n",
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json not found in /home/jackboylan/GLiREL/logs/zero_rel/zero_rel-2024-06-19__16-34-15/model_78000\n",
      "2024-06-20 12:20:48,913 - huggingface_hub.hub_mixin - WARNING - config.json not found in /home/jackboylan/GLiREL/logs/zero_rel/zero_rel-2024-06-19__16-34-15/model_78000\n",
      "/opt/conda/envs/glirel/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:560: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/glirel/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from glirel import GLiREL\n",
    "\n",
    "save_path = 'logs/zero_rel/zero_rel-2024-06-19__16-34-15/model_78000'\n",
    "model = GLiREL.from_pretrained(save_path)\n",
    "# model = GLiREL.from_pretrained('jackboyla/glirel_beta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "\n",
    "To infer, the model needs `tokens`, `NER`, and `zero shot labels`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Derren', 'Nesbitt', 'had', 'a', 'history', 'of', 'being', 'cast', 'in', '\"', 'Doctor', 'Who', '\"', ',', 'having', 'played', 'villainous', 'warlord', 'Tegana', 'in', 'the', '1964', 'First', 'Doctor', 'serial', '\"', 'Marco', 'Polo', '\"', '.']\n",
      "\n",
      "[[26, 27, 'Q2989881', 'Marco Polo'], [22, 23, 'Q2989412', 'First Doctor']]\n",
      "['characters']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('./data/few_rel_all.jsonl', 'r') as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "\n",
    "i = 0\n",
    "\n",
    "tokens = data[i]['tokenized_text']\n",
    "ner = data[i]['ner']\n",
    "labels = list(set([r['relation_text'] for r in data[i]['relations']]))\n",
    "print(tokens)\n",
    "print()\n",
    "print(ner)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['country of origin', 'licensed to broadcast to', 'father', 'followed by', 'characters']\n"
     ]
    }
   ],
   "source": [
    "labels = ['country of origin', 'licensed to broadcast to', 'father', 'followed by'] + labels\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of relations: 10\n",
      "\n",
      "Descending Order by Score:\n",
      "{'head_pos': [26, 28], 'tail_pos': [22, 24], 'head_text': ['Marco', 'Polo'], 'tail_text': ['First', 'Doctor'], 'label': 'followed by', 'score': 0.011230885982513428}\n",
      "{'head_pos': [22, 24], 'tail_pos': [26, 28], 'head_text': ['First', 'Doctor'], 'tail_text': ['Marco', 'Polo'], 'label': 'characters', 'score': 0.010938132181763649}\n",
      "{'head_pos': [22, 24], 'tail_pos': [26, 28], 'head_text': ['First', 'Doctor'], 'tail_text': ['Marco', 'Polo'], 'label': 'followed by', 'score': 0.010783118195831776}\n",
      "{'head_pos': [26, 28], 'tail_pos': [22, 24], 'head_text': ['Marco', 'Polo'], 'tail_text': ['First', 'Doctor'], 'label': 'characters', 'score': 0.01027392502874136}\n",
      "{'head_pos': [26, 28], 'tail_pos': [22, 24], 'head_text': ['Marco', 'Polo'], 'tail_text': ['First', 'Doctor'], 'label': 'father', 'score': 0.0004802523762919009}\n",
      "{'head_pos': [22, 24], 'tail_pos': [26, 28], 'head_text': ['First', 'Doctor'], 'tail_text': ['Marco', 'Polo'], 'label': 'father', 'score': 0.00039520618156529963}\n",
      "{'head_pos': [26, 28], 'tail_pos': [22, 24], 'head_text': ['Marco', 'Polo'], 'tail_text': ['First', 'Doctor'], 'label': 'licensed to broadcast to', 'score': 0.0002560171706136316}\n",
      "{'head_pos': [22, 24], 'tail_pos': [26, 28], 'head_text': ['First', 'Doctor'], 'tail_text': ['Marco', 'Polo'], 'label': 'licensed to broadcast to', 'score': 0.00021301423839759082}\n",
      "{'head_pos': [26, 28], 'tail_pos': [22, 24], 'head_text': ['Marco', 'Polo'], 'tail_text': ['First', 'Doctor'], 'label': 'country of origin', 'score': 0.00020898687944281846}\n",
      "{'head_pos': [22, 24], 'tail_pos': [26, 28], 'head_text': ['First', 'Doctor'], 'tail_text': ['Marco', 'Polo'], 'label': 'country of origin', 'score': 0.0001598332601133734}\n"
     ]
    }
   ],
   "source": [
    "relations = model.predict_relations(tokens, labels, threshold=0.0, ner=ner)\n",
    "\n",
    "print('Number of relations:', len(relations))  # num entity pairs (both directions) * num classes.... provided they're over the threshold\n",
    "\n",
    "sorted_data_desc = sorted(relations, key=lambda x: x['score'], reverse=True)\n",
    "print(\"\\nDescending Order by Score:\")\n",
    "for item in sorted_data_desc:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real-world example\n",
    "\n",
    "Constrain the entity types that can associated with a relationship.\n",
    "e.g:\n",
    "\n",
    "`co-founder` can only have a head `PERSON` entity and a tail `ORG` entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Apple Inc. was founded by Steve Jobs, Steve Wozniak, and Ronald Wayne in April 1976. The company is headquartered in Cupertino, California.\n",
      "Entities detected: [[0, 1, 'ORG', 'Apple Inc.'], [5, 6, 'PERSON', 'Steve Jobs'], [8, 9, 'PERSON', 'Steve Wozniak'], [12, 13, 'PERSON', 'Ronald Wayne'], [15, 16, 'DATE', 'April 1976'], [23, 23, 'GPE', 'Cupertino'], [25, 25, 'GPE', 'California']]\n",
      "Constraining relations by entity type\n",
      "Number of relations: 6\n",
      "\n",
      "Descending Order by Score:\n",
      "['Apple', 'Inc.'] --> headquartered in --> ['Cupertino'] | score: 0.9072741866111755\n",
      "['Apple', 'Inc.'] --> headquartered in --> ['California'] | score: 0.8888104557991028\n",
      "['Apple', 'Inc.'] --> founded on date --> ['April', '1976'] | score: 0.8402661681175232\n",
      "['Steve', 'Jobs'] --> founder --> ['Apple', 'Inc.'] | score: 0.8150324821472168\n",
      "['Steve', 'Wozniak'] --> founder --> ['Apple', 'Inc.'] | score: 0.8128281831741333\n",
      "['Ronald', 'Wayne'] --> founder --> ['Apple', 'Inc.'] | score: 0.7810325026512146\n"
     ]
    }
   ],
   "source": [
    "# Real-world example\n",
    "import spacy\n",
    "from glirel.modules.utils import constrain_relations_by_entity_type\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "\n",
    "text = \"Apple Inc. was founded by Steve Jobs, Steve Wozniak, and Ronald Wayne in April 1976. The company is headquartered in Cupertino, California.\"\n",
    "\n",
    "# text = \"Jack Dorsey's father, Tim Dorsey, is a licensed pilot. Jack met his wife Sarah Paulson in New York in 2003. They have one son, Edward.\"\n",
    "\n",
    "labels = {\"glirel_labels\": {\n",
    "    'co-founder': {\"allowed_head\": [\"PERSON\"], \"allowed_tail\": [\"ORG\"]}, \n",
    "    'country of origin': {\"allowed_head\": [\"PERSON\", \"ORG\"], \"allowed_tail\": [\"LOC\", \"GPE\"]}, \n",
    "    'licensed to broadcast to': {\"allowed_head\": [\"ORG\"]},  \n",
    "    'no relation': {},  \n",
    "    'parent': {\"allowed_head\": [\"PERSON\"], \"allowed_tail\": [\"PERSON\"]}, \n",
    "    'followed by': {\"allowed_head\": [\"PERSON\", \"ORG\"], \"allowed_tail\": [\"PERSON\", \"ORG\"]},  \n",
    "    'located in or next to body of water': {\"allowed_head\": [\"LOC\", \"GPE\", \"FAC\"], \"allowed_tail\": [\"LOC\", \"GPE\"]},  \n",
    "    'spouse': {\"allowed_head\": [\"PERSON\"], \"allowed_tail\": [\"PERSON\"]},  \n",
    "    'child': {\"allowed_head\": [\"PERSON\"], \"allowed_tail\": [\"PERSON\"]},  \n",
    "    'founder': {\"allowed_head\": [\"PERSON\"], \"allowed_tail\": [\"ORG\"]},  \n",
    "    'founded on date': {\"allowed_head\": [\"ORG\"], \"allowed_tail\": [\"DATE\"]},\n",
    "    'headquartered in': {\"allowed_head\": [\"ORG\"], \"allowed_tail\": [\"LOC\", \"GPE\", \"FAC\"]},  \n",
    "    'acquired by': {\"allowed_head\": [\"ORG\"], \"allowed_tail\": [\"ORG\", \"PERSON\"]},  \n",
    "    'subsidiary of': {\"allowed_head\": [\"ORG\"], \"allowed_tail\": [\"ORG\", \"PERSON\"]}, \n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "def predict_and_show(text, labels):\n",
    "    doc = nlp(text)\n",
    "    print(f\"Text: {text}\")\n",
    "\n",
    "    tokens = [token.text for token in doc]\n",
    "\n",
    "    # NOTE: the end index should be inclusive\n",
    "    ner = [[ent.start, (ent.end - 1), ent.label_, ent.text] for ent in doc.ents]\n",
    "    print(f\"Entities detected: {ner}\")\n",
    "\n",
    "    labels_and_constraints = None\n",
    "    if isinstance(labels, dict):\n",
    "        labels = labels[\"glirel_labels\"]\n",
    "        labels_and_constraints = labels\n",
    "        labels = list(labels.keys())\n",
    "\n",
    "    relations = model.predict_relations(tokens, labels, threshold=0.0, ner=ner, top_k=1)\n",
    "\n",
    "    if isinstance(labels_and_constraints, dict):\n",
    "        print('Constraining relations by entity type')\n",
    "        relations = constrain_relations_by_entity_type(doc.ents, labels_and_constraints, relations)\n",
    "\n",
    "    print('Number of relations:', len(relations))\n",
    "\n",
    "    sorted_data_desc = sorted(relations, key=lambda x: x['score'], reverse=True)\n",
    "    print(\"\\nDescending Order by Score:\")\n",
    "    for item in sorted_data_desc:\n",
    "        print(f\"{item['head_text']} --> {item['label']} --> {item['tail_text']} | score: {item['score']}\")\n",
    "\n",
    "predict_and_show(text, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple list of relation types can also be passed, although this generally results in noisier results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Jack knows Gill. They live in the same house in London. They are not related.\n",
      "Entities detected: [[0, 0, 'PERSON', 'Jack'], [2, 2, 'PERSON', 'Gill'], [11, 11, 'GPE', 'London']]\n",
      "Number of relations: 6\n",
      "\n",
      "Descending Order by Score:\n",
      "['Jack'] --> lives in --> ['London'] | score: 0.9570847153663635\n",
      "['Gill'] --> lives in --> ['London'] | score: 0.9562698006629944\n",
      "['Jack'] --> knows --> ['Gill'] | score: 0.8528702259063721\n",
      "['Gill'] --> knows --> ['Jack'] | score: 0.8421204090118408\n",
      "['London'] --> lives in --> ['Gill'] | score: 0.6627970337867737\n",
      "['London'] --> lives in --> ['Jack'] | score: 0.6488385796546936\n"
     ]
    }
   ],
   "source": [
    "text = \"Jack knows Gill. They live in the same house in London. They are not related.\"\n",
    "labels = ['family relation', 'knows', 'lives with', 'loves', 'licensed to broadcast to', 'father', 'followed by', 'no relation', 'lives in',]\n",
    "predict_and_show(text, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/jackboylan/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bcf8fc4b83f4bfe82215ac0bd0dcfec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.87G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/jackboyla/glirel_beta/commit/9d864f1374760c9d5d9321a25d93bdf8895d0964', commit_message='Push model using huggingface_hub.', commit_description='', oid='9d864f1374760c9d5d9321a25d93bdf8895d0964', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import huggingface_hub\n",
    "# import os\n",
    "\n",
    "# huggingface_hub.login(os.environ['HF_TOKEN'])\n",
    "\n",
    "# model.save_pretrained(\n",
    "#     './release_model/glirel_beta', \n",
    "#     push_to_hub=True, \n",
    "#     repo_id='jackboyla/glirel_beta'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gliner_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
